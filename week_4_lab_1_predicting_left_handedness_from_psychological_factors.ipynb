{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### 1. In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Right handed may imply that the right brain lobe activities dominates. So based on the right-brain function, I am wondering if the left-handed people have:\n",
    "\n",
    "1. art awareness,\n",
    "2. stronger creativity and imagination, and\n",
    "3. low interest in prefer math or science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data, delimiter is 'tab' or '\\t'\n",
    "df = pd.read_csv('data.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  country  fromgoogle  engnat  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1  ...       US           2       1   \n",
       "1   1   5   1   4   2   5   5   4   1    5  ...       CA           2       1   \n",
       "2   1   2   1   1   5   4   3   2   1    4  ...       NL           2       2   \n",
       "3   1   4   1   5   1   4   5   4   3    5  ...       US           2       1   \n",
       "4   5   1   5   1   5   1   5   1   3    1  ...       US           2       1   \n",
       "\n",
       "   age  education  gender  orientation  race  religion  hand  \n",
       "0   22          3       1            1     3         2     3  \n",
       "1   14          1       2            2     6         1     1  \n",
       "2   30          4       1            1     1         1     2  \n",
       "3   18          2       2            5     3         2     2  \n",
       "4   22          3       1            1     3         2     3  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1. Since there are personal/privacy data, the collection process and data should be anonymous. \n",
    "2. If possible, consider carefully if personal private data are necessary. Not to collect unnecessary data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4184, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data size\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4184 entries, 0 to 4183\n",
      "Data columns (total 56 columns):\n",
      "Q1             4184 non-null int64\n",
      "Q2             4184 non-null int64\n",
      "Q3             4184 non-null int64\n",
      "Q4             4184 non-null int64\n",
      "Q5             4184 non-null int64\n",
      "Q6             4184 non-null int64\n",
      "Q7             4184 non-null int64\n",
      "Q8             4184 non-null int64\n",
      "Q9             4184 non-null int64\n",
      "Q10            4184 non-null int64\n",
      "Q11            4184 non-null int64\n",
      "Q12            4184 non-null int64\n",
      "Q13            4184 non-null int64\n",
      "Q14            4184 non-null int64\n",
      "Q15            4184 non-null int64\n",
      "Q16            4184 non-null int64\n",
      "Q17            4184 non-null int64\n",
      "Q18            4184 non-null int64\n",
      "Q19            4184 non-null int64\n",
      "Q20            4184 non-null int64\n",
      "Q21            4184 non-null int64\n",
      "Q22            4184 non-null int64\n",
      "Q23            4184 non-null int64\n",
      "Q24            4184 non-null int64\n",
      "Q25            4184 non-null int64\n",
      "Q26            4184 non-null int64\n",
      "Q27            4184 non-null int64\n",
      "Q28            4184 non-null int64\n",
      "Q29            4184 non-null int64\n",
      "Q30            4184 non-null int64\n",
      "Q31            4184 non-null int64\n",
      "Q32            4184 non-null int64\n",
      "Q33            4184 non-null int64\n",
      "Q34            4184 non-null int64\n",
      "Q35            4184 non-null int64\n",
      "Q36            4184 non-null int64\n",
      "Q37            4184 non-null int64\n",
      "Q38            4184 non-null int64\n",
      "Q39            4184 non-null int64\n",
      "Q40            4184 non-null int64\n",
      "Q41            4184 non-null int64\n",
      "Q42            4184 non-null int64\n",
      "Q43            4184 non-null int64\n",
      "Q44            4184 non-null int64\n",
      "introelapse    4184 non-null int64\n",
      "testelapse     4184 non-null int64\n",
      "country        4184 non-null object\n",
      "fromgoogle     4184 non-null int64\n",
      "engnat         4184 non-null int64\n",
      "age            4184 non-null int64\n",
      "education      4184 non-null int64\n",
      "gender         4184 non-null int64\n",
      "orientation    4184 non-null int64\n",
      "race           4184 non-null int64\n",
      "religion       4184 non-null int64\n",
      "hand           4184 non-null int64\n",
      "dtypes: int64(55), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data type and null info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm there is no null value\n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "This would be a classification problem because the expected model output is binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "When the scale of the variables impact the model parameters or model output, we want to standardize the variables to equalize the contribution from each variable to the model. \n",
    "\n",
    "**Example 1: KNN Model**\n",
    "1. KNN model is distance based model. \n",
    "2. Distance is calculated based on the absolute difference of each variables.\n",
    "3. Because viariables with different units have different scale, their contribution to the distance varies.\n",
    "4. Standardizing the variable (normally using the z-score of the variable) equalizes the contribution from each variables to the same measures. \n",
    "\n",
    "**Example 2: Ridge/Lasso**\n",
    "1. The scale of the variables affects the regularization term in Ridge/Lasso model. The parameter (i.e., beta) for variable with larger scale gets penalized heavier.  \n",
    "2. Standardizing the variable equalizes the penalty to each variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "**Simple Linear Regression** (does not have regulaziation based on the variable scale) do not need data standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Based on your answers to 6 and 7, do you think we should standardize our predictor variables in this case? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "**No, we do not.** Altough we are running KNN which is a distance based model, Q1-Q44 were valued using the same score system. Therefore, the contributions from all question/feature to the distance are already equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Based on codebook.txt, the hand column should only have three unique values, which are 1 (right), 2 (left), and 3 (both). Since there is no good way to estimate the value if the value is missing or incorrect, data with values other than [1, 2, or 3] is disqualified for this study and should be deleted.\n",
    "\n",
    "2. Since the problem is whether a person is left-handed. Map \"2\"(left-handed) to 1 and the rest to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique value\n",
    "df['hand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a function for deleting disqualified data\n",
    "'''Delete rows with bad data (data not in the list_of_good_data)\n",
    "   Input: \n",
    "         df: pandas DataFrame, target dataframe\n",
    "         feat: str, feature of interest\n",
    "         list_of_good_data: list of good data\n",
    "         summary (optional): boolean, to print the removed bad data\n",
    "   return: dataframe\n",
    "'''\n",
    "def del_bad_data(df, feat, list_of_good_data, summary=False):  \n",
    "    if df[feat].nunique() > len(list_of_good_data):  # if true, there is unexpected value\n",
    "        bad_data = ~df[feat].isin(list_of_good_data) # mask for bad data\n",
    "        print(f'Rows before cleaning: {df.shape[0]}')\n",
    "        print(f'Number of disqualified and removed data: {df[bad_data].shape[0]}')\n",
    "   \n",
    "        if summary == True:\n",
    "            print(df[bad_data])  # print the bad data   \n",
    "        \n",
    "        df.drop(df[bad_data].index, inplace=True) # remove the bad data and return the clean df\n",
    "        print(f'Rows after cleaning: {df.shape[0]}')\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        print('Your data is clean! Nothing to delete')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 4184\n",
      "Number of disqualified and removed data: 11\n",
      "Rows after cleaning: 4173\n"
     ]
    }
   ],
   "source": [
    "# Clean the data\n",
    "df = del_bad_data(df, 'hand', [1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hand'] = df['hand'].apply(lambda x: 1 if x == 2 else 0)\n",
    "df['hand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4173, 56)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The professor for whom you work suggests that you set $k = 4$. In this specific case, why might this be a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Where a person is left-handed is a binary problem. For binary outcome, using even number for k may lead to unconclusive model output (e.g, '0' = '1' = 2). Using odd number for k instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine X and y\n",
    "X = df.iloc[:, 0:44]\n",
    "y = df['hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  Q35  Q36  Q37  Q38  Q39  Q40  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1  ...    5    1    1    1    5    5   \n",
       "1   1   5   1   4   2   5   5   4   1    5  ...    4    4    4    4    1    3   \n",
       "2   1   2   1   1   5   4   3   2   1    4  ...    2    2    4    2    1    4   \n",
       "3   1   4   1   5   1   4   5   4   3    5  ...    5    1    3    4    1    2   \n",
       "4   5   1   5   1   5   1   5   1   3    1  ...    5    1    1    1    5    5   \n",
       "\n",
       "   Q41  Q42  Q43  Q44  \n",
       "0    5    1    5    1  \n",
       "1    1    4    4    5  \n",
       "2    2    2    2    2  \n",
       "3    1    1    1    3  \n",
       "4    5    1    5    1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k\n",
    "ks = [3, 5, 15, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for model with k values\n",
    "'''run knn model\n",
    "   input:\n",
    "        X_train: DataFrame, training features\n",
    "        X_test: DataFrame, testing features\n",
    "        y_train: Series, training targets\n",
    "        y_test: Series, testing targets\n",
    "        k: int, n_neighbor\n",
    "    return:\n",
    "        y_pred (list), cv_score (float), r2_score_train (float), r2_score_test (float)\n",
    "   \n",
    "   '''\n",
    "def run_knn(X_train, X_test, y_train, y_test, k):\n",
    "    print(f'When k = {k}:')\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=k) # Instantiate model\n",
    "    knn.fit(X_train, y_train)                 # Fit model\n",
    "    \n",
    "    cv_score = cross_val_score(knn, X_train, y_train, cv=10).mean() # cross validation\n",
    "    accuracy_train = knn.score(X_train, y_train) # R2 score for training\n",
    "    accuracy_test = knn.score(X_test, y_test) # R2 score for testing\n",
    "    y_pred = knn.predict(X_test)              # predict y\n",
    "    cm = confusion_matrix(y_test, y_pred)     # confustion matrix\n",
    "    cm_df = pd.DataFrame(cm, columns = ['pred_right', 'pred_left'], \n",
    "                             index = ['actual_right', 'actual_left'])\n",
    "    print(f' The cross validation score is: {cv_score}')\n",
    "    print(f' The train data accuracy is: {accuracy_train}')\n",
    "    print(f' The testing data accuracy is: {accuracy_test}')\n",
    "    print(f' The confusion matrix: \\n{cm_df}\\n')\n",
    "    return y_pred, cv_score, accuracy_train, accuracy_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When k = 3:\n",
      " The cross validation score is: 0.8600229376587205\n",
      " The train data accuracy is: 0.9060402684563759\n",
      " The testing data accuracy is: 0.8486590038314177\n",
      " The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         882         49\n",
      "actual_left          109          4\n",
      "\n",
      "When k = 5:\n",
      " The cross validation score is: 0.8772814778405833\n",
      " The train data accuracy is: 0.8935762224352828\n",
      " The testing data accuracy is: 0.8735632183908046\n",
      " The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         909         22\n",
      "actual_left          110          3\n",
      "\n",
      "When k = 15:\n",
      " The cross validation score is: 0.8916594986483167\n",
      " The train data accuracy is: 0.8916586768935763\n",
      " The testing data accuracy is: 0.8917624521072797\n",
      " The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         931          0\n",
      "actual_left          113          0\n",
      "\n",
      "When k = 25:\n",
      " The cross validation score is: 0.8916594986483167\n",
      " The train data accuracy is: 0.8916586768935763\n",
      " The testing data accuracy is: 0.8917624521072797\n",
      " The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         931          0\n",
      "actual_left          113          0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run model with k values\n",
    "y_preds_knn = pd.DataFrame()\n",
    "cm_knn = []\n",
    "cv_scores_knn = []\n",
    "accuracy_train_knn = []\n",
    "accuracy_test_knn = []\n",
    "\n",
    "for k in ks:\n",
    "    y_pred, cv_score, accuracy_train, accuracy_test, cm = run_knn(X_train, X_test, y_train, y_test, k) # run model\n",
    "    y_preds_knn[k] = y_pred \n",
    "    cv_scores_knn.append(cv_score)\n",
    "    accuracy_train_knn.append(accuracy_train)\n",
    "    accuracy_test_knn.append(accuracy_test)\n",
    "    cm_knn.append(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 12. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Yes, the regularization is applied by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "No. Although Logistic Regression applies regularization, we do not need to standardize because all our features are valued using the same scale system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Let's use logistic regression to predict whether or not the person is left-handed.\n",
    "\n",
    "\n",
    "> Be sure to use the same train/test split with your data as with your $k$-NN model above!\n",
    "\n",
    "> Create four separate models, one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regularization and alpha\n",
    "regs = ['l1', 'l2'] # 'l1' = Lasso, 'l2' = Ridge\n",
    "alphas = [1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run Logistic Regression\n",
    "'''Input:\n",
    "        X_train: DataFrame, X training data\n",
    "        X_test: Dataframe, X testinng data\n",
    "        y_train: pd Series, y training data\n",
    "        y_test: pd Series, y training dta\n",
    "        reg: str ('l1': lasso, or 'l2': ridge)\n",
    "        alpha: regulation coefficient\n",
    "'''\n",
    "\n",
    "def run_lr(X_train, X_test, y_train, y_test, reg, alpha):\n",
    "    print('Regularization: Lasso' if reg == 'l1' else 'Regularization: Ridge')\n",
    "    print(f'  When alpha = {alpha}')\n",
    "    lr = LogisticRegression(penalty=reg, C=(1/alpha), solver='liblinear')\n",
    "    lr.fit(X_train, y_train)\n",
    "    cv_score = cross_val_score(lr, X_train, y_train, cv=10).mean()\n",
    "    y_pred = lr.predict(X_test)\n",
    "    accuracy_train = lr.score(X_train, y_train)\n",
    "    accuracy_test = lr.score(X_test, y_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, columns = ['pred_right', 'pred_left'], \n",
    "                                                           index = ['actual_right', 'actual_left'])\n",
    "    coef = lr.coef_\n",
    "    print(f'    The cross validation score is: {cv_score}')\n",
    "    print(f'    The train data accuracy is: {accuracy_train}')\n",
    "    print(f'    The testing data accracy is: {accuracy_test}')\n",
    "    print(f'    The confusion matrix: \\n{cm_df}\\n')\n",
    "    return y_pred, cv_score, accuracy_train, accuracy_test, cm, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization: Lasso\n",
      "  When alpha = 1\n",
      "    The cross validation score is: 0.891978987466208\n",
      "    The train data accuracy is: 0.891978267817194\n",
      "    The testing data accracy is: 0.8917624521072797\n",
      "    The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         931          0\n",
      "actual_left          113          0\n",
      "\n",
      "Regularization: Lasso\n",
      "  When alpha = 10\n",
      "    The cross validation score is: 0.891978987466208\n",
      "    The train data accuracy is: 0.891978267817194\n",
      "    The testing data accracy is: 0.8917624521072797\n",
      "    The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         931          0\n",
      "actual_left          113          0\n",
      "\n",
      "Regularization: Ridge\n",
      "  When alpha = 1\n",
      "    The cross validation score is: 0.8916594986483167\n",
      "    The train data accuracy is: 0.891978267817194\n",
      "    The testing data accracy is: 0.8917624521072797\n",
      "    The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         931          0\n",
      "actual_left          113          0\n",
      "\n",
      "Regularization: Ridge\n",
      "  When alpha = 10\n",
      "    The cross validation score is: 0.891978987466208\n",
      "    The train data accuracy is: 0.891978267817194\n",
      "    The testing data accracy is: 0.8917624521072797\n",
      "    The confusion matrix: \n",
      "              pred_right  pred_left\n",
      "actual_right         931          0\n",
      "actual_left          113          0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run model with penalty and alpha values\n",
    "y_preds_lr = []\n",
    "cv_scores_lr = []\n",
    "r2_scores_train_lr = []\n",
    "r2_scores_test_lr = []\n",
    "cm_lr = []\n",
    "coef_lr_alpha = {}\n",
    "coef_lr = {}\n",
    "\n",
    "for reg in regs:\n",
    "    for alpha in alphas:\n",
    "        y_pred_lr, cv_score_lr, accuracy_train_lr, accuracy_test_lr, cm, coef = \\\n",
    "                 run_lr(X_train, X_test, y_train, y_test, reg, alpha)\n",
    "        y_preds_lr.append(y_pred)\n",
    "        cv_scores_lr.append(cv_score)\n",
    "        r2_scores_train_lr.append(accuracy_train)\n",
    "        r2_scores_test_lr.append(accuracy_test)\n",
    "        cm_lr.append(cm)\n",
    "        coef_lr_alpha[str(alpha)] = coef.ravel()\n",
    "    coef_lr[reg] = coef_lr_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 15. Before calculating any score on your data, take a step back. Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not? What impact do you think this will have on your scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I think therea are too many features in the X varriables (44 of them), which makes the true impact very unclear. Too many features usually causes the model to be overfit. A overfit model usually have low bias and high variance. A high variance model usually does poor job on predicting y variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Using accuracy as your metric, evaluate all eight of your models on both the training and testing sets. Put your scores below. (If you want to be fancy and generate a table in Markdown, there's a [Markdown table generator site linked here](https://www.tablesgenerator.com/markdown_tables#).)\n",
    "- Note: Your answers here might look a little weird. You didn't do anything wrong; that's to be expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "$$ precision = (TP + TN) / All Prediction$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k-NN Model**\n",
    "\n",
    "**K Value**|**TP**|**TN**|**FP**|**FN**|**Precision**\n",
    ":-----:|:-----:|:-----:|:-----:|:-----:|:-----:\n",
    "3|4|882|49|109|0.848659004\n",
    "5|3|909|22|110|0.873563218\n",
    "15|0|931|0|113|0.891762452\n",
    "25|0|931|0|113|0.891762452\n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "**Model**|**Alpha**|**TP**|**TN**|**FP**|**FN**|**Precision**\n",
    ":-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:\n",
    "Lasso|1|0|931|0|113|0.891762452\n",
    "Lasso|10|0|931|0|113|0.891762452\n",
    "Ridge|1|0|931|0|113|0.891762452\n",
    "Ridge|10|0|931|0|113|0.891762452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In which of your $k$-NN models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "When k = 3 and k = 5, the k-NN models are overfitting. The accuracy for training data is higher than accuracy for the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "As k increase, \n",
    "1. bias increase because accuracy drops\n",
    "2. variance decrease because the accuracy are getting closer. Also the results becomes more consistent for k > 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1. Reduce the number of featues.\n",
    "2. Choose the right K.\n",
    "3. Increase the size of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. In which of your logistic regression models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Since my logistic regression has low variance, I don't think my models are overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Based on the documentary, C is the inverse of regularization strengh. Therefore, the higher the C is, the weaker the regularization (lower punishment). Bias tends to be low and variance tends to be high. Low C has the opposite affects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What do you think this means in the context of this specific problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "In this model, the change of C has no impact to the fit and coefficients in the model.\n",
    "\n",
    "Larger Alpha actually decreses the coefficients. This makes sense because the higher regularization decreases the sensitivity of the features (by shrinking the coefficient / or making the line flatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': {'1': array([-0.03306998,  0.01481416,  0.04778889, -0.08656532,  0.05177639,\n",
       "         -0.06143164,  0.00746298, -0.16962719, -0.04274797,  0.02341422,\n",
       "          0.01535305,  0.04075753, -0.02567381,  0.03105701, -0.02238169,\n",
       "          0.02857004,  0.02124619, -0.02161584, -0.04156337, -0.05254099,\n",
       "         -0.1002466 , -0.07123465, -0.03089169, -0.02166746, -0.00698333,\n",
       "          0.14128654,  0.08317938,  0.01977726,  0.03642763,  0.0324297 ,\n",
       "          0.0145622 , -0.03817322,  0.00701537, -0.05049121,  0.03001425,\n",
       "         -0.02433674, -0.04516399,  0.09215549, -0.05355036, -0.07777899,\n",
       "         -0.04639833, -0.06308872, -0.14682989, -0.02801699]),\n",
       "  '10': array([-0.03378078,  0.01274694,  0.04686127, -0.08484905,  0.05090015,\n",
       "         -0.06154275,  0.00557998, -0.16796954, -0.04359203,  0.02046491,\n",
       "          0.01316768,  0.03760781, -0.02791098,  0.02965609, -0.0213712 ,\n",
       "          0.02732356,  0.02179564, -0.02219455, -0.04263888, -0.05317671,\n",
       "         -0.09989373, -0.07173797, -0.03192601, -0.023236  , -0.00800273,\n",
       "          0.13779699,  0.06867319,  0.02001916,  0.03527216,  0.03140203,\n",
       "          0.01173986, -0.038532  ,  0.00390117, -0.05063218,  0.02885619,\n",
       "         -0.02520754, -0.04569362,  0.08869155, -0.05166842, -0.07607043,\n",
       "         -0.04714774, -0.06199546, -0.1320196 , -0.02818831])},\n",
       " 'l2': {'1': array([-0.03306998,  0.01481416,  0.04778889, -0.08656532,  0.05177639,\n",
       "         -0.06143164,  0.00746298, -0.16962719, -0.04274797,  0.02341422,\n",
       "          0.01535305,  0.04075753, -0.02567381,  0.03105701, -0.02238169,\n",
       "          0.02857004,  0.02124619, -0.02161584, -0.04156337, -0.05254099,\n",
       "         -0.1002466 , -0.07123465, -0.03089169, -0.02166746, -0.00698333,\n",
       "          0.14128654,  0.08317938,  0.01977726,  0.03642763,  0.0324297 ,\n",
       "          0.0145622 , -0.03817322,  0.00701537, -0.05049121,  0.03001425,\n",
       "         -0.02433674, -0.04516399,  0.09215549, -0.05355036, -0.07777899,\n",
       "         -0.04639833, -0.06308872, -0.14682989, -0.02801699]),\n",
       "  '10': array([-0.03378078,  0.01274694,  0.04686127, -0.08484905,  0.05090015,\n",
       "         -0.06154275,  0.00557998, -0.16796954, -0.04359203,  0.02046491,\n",
       "          0.01316768,  0.03760781, -0.02791098,  0.02965609, -0.0213712 ,\n",
       "          0.02732356,  0.02179564, -0.02219455, -0.04263888, -0.05317671,\n",
       "         -0.09989373, -0.07173797, -0.03192601, -0.023236  , -0.00800273,\n",
       "          0.13779699,  0.06867319,  0.02001916,  0.03527216,  0.03140203,\n",
       "          0.01173986, -0.038532  ,  0.00390117, -0.05063218,  0.02885619,\n",
       "         -0.02520754, -0.04569362,  0.08869155, -0.05166842, -0.07607043,\n",
       "         -0.04714774, -0.06199546, -0.1320196 , -0.02818831])}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1. Reduce the number of features\n",
    "2. Strenghening the regularization\n",
    "3. Increase the size of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 24. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I would use logistic regression becuase logistic regression is parametric model. The coefficient or beta quantifies the change of left-handedness with respect to 1 unit change of the feature. \n",
    "\n",
    "k-NN is non-parametric model and therefore cannot be used for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Select your logistic regression model that utilized LASSO regularization with $\\alpha = 1$. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for Q1 is -0.03306998192365425\n",
      "One unit increase/decrease in Q1 will decrease/increase the odds of being left-handed by 0.9674708517486124 times\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficient of Q1 in Lasso regularization with alpha = 1\n",
    "Q1_coef = coef_lr[\"l1\"][\"1\"][0]\n",
    "\n",
    "print(f'The coefficient for Q1 is {Q1_coef}')\n",
    "print(f'One unit increase/decrease in Q1 will decrease/increase the odds of being left-handed by {np.exp(Q1_coef)}\\\n",
    " times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic function can be written as: $p/(1-p) = e^{beta*Q1}*e^{beta*Q2}$.....\n",
    "So one unit change in Q1 would decrease the odds by $e^{-0.033}$ or 0.97 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. If you have to select one model overall to be your *best* model, which model would you select? Why?\n",
    "- Usually in the \"real world,\" you'll fit many types of models but ultimately need to pick only one! (For example, a client may not understand what it means to have multiple models, or if you're using an algorithm to make a decision, it's probably pretty challenging to use two or more algorithms simultaneously.) It's not always an easy choice, but you'll have to make it soon enough. Pick a model and defend why you picked this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I would choose a parametric model like Logistic Regression with Regularization (Alpha = 10, or C = 0.1). With parametric informaiton with stronger regularization (stronger penalty for overfitting), I will be able to understand and explain what features are more important than the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer one of these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "My third conclusion is that left-handed people have low interest in math or science. The coefficient is negative which is consistent with my conclusion.\n",
    "\n",
    "The coefficient means the more the person like the math class, the less likely he/she is left-handed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.025673805434385053"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficient for Q13: I would prefer a class in mathematics to a class in pottery.\n",
    "coef_lr['l1']['1'][12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following. (They could make for a blog post!)\n",
    "- Create a visual plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?\n",
    "- Fit and evaluate a generalized linear model other than logistic regression (e.g. Poisson regression).\n",
    "- Suppose this data were in a `SQL` database named `data` and a table named `inventory`. What `SQL` query would return the count of people who were right-handed, left-handed, both, or missing with their class labels of 1, 2, 3, and 0, respectively? (You can assume you've already logged into the database.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
